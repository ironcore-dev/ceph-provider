name: Run integration tests

on:
  pull_request:
    types: [labeled, synchronize, reopened]
    paths-ignore:
      - 'docs/**'

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'integration-tests')

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - uses: actions/setup-go@v4
        with:
          go-version-file: 'go.mod'

      - name: Setup MicroCeph
        run: |
          set -x
          sudo apt-get install --no-install-recommends -y snapd ceph-common
          sudo snap install microceph --edge
          sleep 5
          sudo microceph cluster bootstrap
          sudo microceph.ceph config set global osd_pool_default_size 1
          sudo microceph.ceph config set global mon_allow_pool_delete true
          sudo microceph.ceph config set global osd_memory_target 939524096
          sudo microceph.ceph osd crush rule rm replicated_rule
          sudo microceph.ceph osd crush rule create-replicated replicated default osd
          for flag in nosnaptrim noscrub nobackfill norebalance norecover noscrub nodeep-scrub; do
              sudo microceph.ceph osd set $flag
          done
          # Use ephemeral disk mounted on /mnt for ceph OSD.
          # The block-devices plug doesn't allow accessing /dev/loopX devices so we make those same devices
          # available under alternate names (/dev/sdiY) that are not used inside GitHub Action runners.
          sudo swapoff /mnt/swapfile
          sudo rm -f /mnt/swapfile
          loop_file="/mnt/ceph-osd.img"
          sudo fallocate -l 10G "${loop_file}"
          loop_dev="$(sudo losetup --show --direct-io=on --nooverlap -f "${loop_file}")"
          devInfo=($(sudo stat -c '%t %T' "${loop_dev}"))
          sudo mknod -m 0660 /dev/sdia b 0x"${devInfo[0]}" 0x"${devInfo[1]}"
          sudo microceph disk add --wipe /dev/sdia
          sudo rm -rf /etc/ceph
          sudo ln -s /var/snap/microceph/current/conf/ /etc/ceph
          sudo microceph enable rgw
          sudo ceph osd pool create devpool 8

      - name: Waiting for Ceph cluster and pools to be healthy
        run: |
          # Check Ceph Health
          for i in {1..30}; do
            health_status=$(ceph health | awk '{print $1}')
            if [[ "$health_status" == "HEALTH_OK" || "$health_status" == "HEALTH_WARN" ]]; then
              echo "Ceph is in an acceptable state: health_status."
              break
            fi
              echo "Waiting for Ceph to reach a stable state..."
              sleep 10
          done

          # Check Pools
          pool_to_check="devpool"
          pool_ready=false
          for i in {1..30}; do  
            pools=$(ceph osd lspools)
            if [[ "$pools" == *"$pool_to_check"* ]]; then
              pool_ready=true
              break
            fi
            echo "Waiting for $pool_to_check pool to be ready..."
            sleep 10
          done
          if $pool_ready; then
            echo "$pool_to_check pool is ready."
          else
            echo "$pool_to_check pool is not ready. Exiting."
            exit 1
          fi
          
          sudo microceph.ceph status
          sudo rm -f /snap/bin/rbd

      - name: Set Environment Variables
        run: |
          echo "CEPH_USERNAME=admin" >> $GITHUB_ENV
          echo "CEPH_POOLNAME=devpool" >> $GITHUB_ENV
          echo "CEPH_CLIENTNAME=client.admin" >> $GITHUB_ENV
          echo "CEPH_KEYRING_FILENAME=/etc/ceph/ceph.client.admin.keyring" >> $GITHUB_ENV
          echo "CEPH_MONITORS=$(hostname):6789" >> $GITHUB_ENV
          echo "CEPH_CONFIG_FILE=/etc/ceph/ceph.conf" >> $GITHUB_ENV
          sudo chmod +r /etc/ceph/ceph.client.admin.keyring

      - name: Install dependencies
        run: |
          sudo apt install -y libcephfs-dev librbd-dev librados-dev

      - name: Run go tests
        run: |
          make integration-tests 
